{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:51:49.984026Z","iopub.status.busy":"2022-06-05T14:51:49.983496Z","iopub.status.idle":"2022-06-05T14:51:59.482562Z","shell.execute_reply":"2022-06-05T14:51:59.481519Z","shell.execute_reply.started":"2022-06-05T14:51:49.983936Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import wave\n","from scipy.io import wavfile\n","import os\n","import librosa\n","from librosa.feature import melspectrogram\n","import warnings\n","from sklearn.utils import shuffle\n","from sklearn.utils import class_weight\n","from PIL import Image\n","from uuid import uuid4\n","import sklearn\n","from tqdm import tqdm\n","import IPython.display as ipd\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Rescaling\n","from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, LSTM, SimpleRNN, Conv1D, Input, BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import EfficientNetB0\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","\n","seed = 30\n","tf.random.set_seed(seed)\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["**Read files and choose part of them**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:55:45.632617Z","iopub.status.busy":"2022-06-05T14:55:45.632313Z","iopub.status.idle":"2022-06-05T14:55:45.666648Z","shell.execute_reply":"2022-06-05T14:55:45.665970Z","shell.execute_reply.started":"2022-06-05T14:55:45.632586Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\n","train_df = train_df.query(\"rating>=5\")\n","birds_count = {}\n","for bird_species, count in zip(train_df.primary_label.unique(), train_df.groupby(\"primary_label\")[\"primary_label\"].count().values):\n","    birds_count[bird_species] = count\n","chosen_birds = [key for key,value in birds_count.items() if value in range(50,70)]\n","train_df = train_df.query(\"primary_label in @chosen_birds\")\n","train_df = shuffle(train_df)\n","train_df.primary_label.unique()"]},{"cell_type":"markdown","metadata":{},"source":["**Dataset Separation**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:56:26.908570Z","iopub.status.busy":"2022-06-05T14:56:26.908260Z","iopub.status.idle":"2022-06-05T14:56:26.914650Z","shell.execute_reply":"2022-06-05T14:56:26.913809Z","shell.execute_reply.started":"2022-06-05T14:56:26.908529Z"},"trusted":true},"outputs":[],"source":["training_percentage = 0.8\n","training_item_count = int(len(train_df)*0.8)\n","validation_item_count = int(len(train_df)*0.1)\n","test_item_count = int(len(train_df)*0.1)\n","training_df = train_df[:training_item_count]\n","validation_df = train_df[training_item_count:training_item_count+validation_item_count]\n","test_df = train_df[training_item_count+validation_item_count:]"]},{"cell_type":"markdown","metadata":{},"source":["**Rean an audio file as an example**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:56:42.006633Z","iopub.status.busy":"2022-06-05T14:56:42.006323Z","iopub.status.idle":"2022-06-05T14:56:43.498699Z","shell.execute_reply":"2022-06-05T14:56:43.497717Z","shell.execute_reply.started":"2022-06-05T14:56:42.006602Z"},"trusted":true},"outputs":[],"source":["wav, sr = librosa.load(\"../input/birdclef-2021/train_short_audio/amecro/XC109768.ogg\")"]},{"cell_type":"markdown","metadata":{},"source":["**Function of drawing images**"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:56:45.544642Z","iopub.status.busy":"2022-06-05T14:56:45.543281Z","iopub.status.idle":"2022-06-05T14:56:45.550861Z","shell.execute_reply":"2022-06-05T14:56:45.549882Z","shell.execute_reply.started":"2022-06-05T14:56:45.544599Z"},"trusted":true},"outputs":[],"source":["def plot_time_series(data):\n","    fig = plt.figure(figsize=(14, 8))\n","    plt.title('Raw wave ')\n","    plt.ylabel('Amplitude')\n","    plt.plot(np.linspace(0, 1, len(data)), data)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Time Stretch**"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:56:54.481068Z","iopub.status.busy":"2022-06-05T14:56:54.480724Z","iopub.status.idle":"2022-06-05T14:56:54.487393Z","shell.execute_reply":"2022-06-05T14:56:54.486689Z","shell.execute_reply.started":"2022-06-05T14:56:54.481032Z"},"trusted":true},"outputs":[],"source":["def stretch(data, rate=1):\n","    input_length = sr\n","    data = librosa.effects.time_stretch(data, rate)\n","    data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n","    return data\n","\n","data_stretch =stretch(wav, 1.2)\n","ipd.Audio(data_stretch, rate=sr)\n","plot_time_series(data_stretch)"]},{"cell_type":"markdown","metadata":{},"source":["**White noise**"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:57:16.312671Z","iopub.status.busy":"2022-06-05T14:57:16.312326Z","iopub.status.idle":"2022-06-05T14:57:16.847272Z","shell.execute_reply":"2022-06-05T14:57:16.846189Z","shell.execute_reply.started":"2022-06-05T14:57:16.312640Z"},"trusted":true},"outputs":[],"source":["wn = np.random.randn(len(wav))\n","wav_wn = wav + 0.01*wn\n","ipd.Audio(wav_wn, rate=sr)\n","plot_time_series(wav_wn)"]},{"cell_type":"markdown","metadata":{},"source":["**Pitch shifting**"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:57:21.496835Z","iopub.status.busy":"2022-06-05T14:57:21.496513Z","iopub.status.idle":"2022-06-05T14:57:23.044841Z","shell.execute_reply":"2022-06-05T14:57:23.043583Z","shell.execute_reply.started":"2022-06-05T14:57:21.496804Z"},"trusted":true},"outputs":[],"source":["wav_p = librosa.effects.pitch_shift(wav, sr, 4)\n","ipd.Audio(wav_p, rate=sr)\n","plot_time_series(wav)\n","plot_time_series(wav_p)"]},{"cell_type":"markdown","metadata":{},"source":["**The function of getting image samples from audios**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T07:01:47.053134Z","iopub.status.busy":"2022-05-18T07:01:47.052864Z","iopub.status.idle":"2022-05-18T07:01:47.065761Z","shell.execute_reply":"2022-05-18T07:01:47.064729Z","shell.execute_reply.started":"2022-05-18T07:01:47.053105Z"},"trusted":true},"outputs":[],"source":["def get_sample(filename, bird, output_folder):\n","    wave_data, wave_rate = librosa.load(filename)\n","    wave_data, _ = librosa.effects.trim(wave_data)\n","    ## Data augmentation part\n","    wave_data = stretch(wave_data, 1.2)\n","    wn = np.random.randn(len(wave_data))\n","    wave_data = wave_data + 0.01*wn\n","    wave_data = librosa.effects.pitch_shift(wave_data, wave_rate, 4)\n","    \n","    song_sample = []\n","    sample_length = 5*wave_rate\n","    samples_from_file = []\n","    N_mels=216\n","    for idx in range(0,len(wave_data),sample_length): \n","        song_sample = wave_data[idx:idx+sample_length]\n","        if len(song_sample)>=sample_length:\n","            mel = melspectrogram(song_sample, n_mels=N_mels)\n","            db = librosa.power_to_db(mel)\n","            normalised_db = sklearn.preprocessing.minmax_scale(db)\n","            filename = str(uuid4())+\".jpg\"\n","            db_array = (np.asarray(normalised_db)*255).astype(np.uint8)\n","            db_image =  Image.fromarray(np.array([db_array, db_array, db_array]).T)\n","            db_image.save(\"{}{}\".format(output_folder,filename))\n","            \n","            samples_from_file.append({\"song_sample\":\"{}{}\".format(output_folder,filename),\n","                                            \"db\":db_array,\"bird\":bird})\n","    return samples_from_file"]},{"cell_type":"markdown","metadata":{},"source":["**Transform all audios into images**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T07:01:54.497536Z","iopub.status.busy":"2022-05-18T07:01:54.497131Z","iopub.status.idle":"2022-05-18T07:02:08.316709Z","shell.execute_reply":"2022-05-18T07:02:08.315415Z","shell.execute_reply.started":"2022-05-18T07:01:54.497495Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")\n","train_samples = pd.DataFrame(columns=[\"song_sample\",\"bird\"])\n","train_list = []\n","\n","output_folder = \"/kaggle/working/melspectrogram/\"\n","os.mkdir(output_folder)\n","output_folder += \"train/\"\n","os.mkdir(output_folder)\n","with tqdm(total=len(training_df)) as pbar:\n","    for idx, row in training_df.iterrows():\n","        pbar.update(1)\n","        try:\n","            audio_file_path = \"../input/birdclef-2021/train_short_audio/\"\n","            audio_file_path += row.primary_label\n","            if row.primary_label in birds_to_recognise:\n","                outf = output_folder + row.primary_label + \"/\"\n","                if os.path.isdir(outf) == False:\n","                    os.mkdir(outf)\n","                train_list += get_sample('{}/{}'.format(audio_file_path, row.filename), row.primary_label, outf) \n","        except:\n","            raise\n","            print(\"{} is corrupted\".format(audio_file_path))\n","            \n","train_samples = pd.DataFrame(train_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T07:44:57.928253Z","iopub.status.busy":"2022-05-17T07:44:57.927479Z","iopub.status.idle":"2022-05-17T07:45:34.828559Z","shell.execute_reply":"2022-05-17T07:45:34.827735Z","shell.execute_reply.started":"2022-05-17T07:44:57.928206Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")\n","validation_samples = pd.DataFrame(columns=[\"song_sample\",\"bird\"])\n","validation_list = []\n","\n","output_folder = \"/kaggle/working/melspectrogram/validation/\"\n","os.mkdir(output_folder)\n","with tqdm(total=len(validation_df)) as pbar:\n","    for idx, row in validation_df.iterrows():\n","        pbar.update(1)\n","        try:\n","            audio_file_path = \"../input/birdclef-2021/train_short_audio/\"\n","            audio_file_path += row.primary_label\n","            if row.primary_label in birds_to_recognise:\n","                outf = output_folder + row.primary_label + \"/\"\n","                if os.path.isdir(outf) == False:\n","                    os.mkdir(outf)\n","                validation_list += get_sample('{}/{}'.format(audio_file_path, row.filename), row.primary_label, outf) \n","        except:\n","            raise\n","            print(\"{} is corrupted\".format(audio_file_path))\n","            \n","validation_samples = pd.DataFrame(validation_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T07:45:37.117103Z","iopub.status.busy":"2022-05-17T07:45:37.116808Z","iopub.status.idle":"2022-05-17T07:46:12.44949Z","shell.execute_reply":"2022-05-17T07:46:12.448727Z","shell.execute_reply.started":"2022-05-17T07:45:37.117074Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")\n","test_samples = pd.DataFrame(columns=[\"song_sample\",\"bird\"])\n","test_list = []\n","\n","output_folder = \"/kaggle/working/melspectrogram/test/\"\n","os.mkdir(output_folder)\n","with tqdm(total=len(test_df)) as pbar:\n","    for idx, row in test_df.iterrows():\n","        pbar.update(1)\n","        try:\n","            audio_file_path = \"../input/birdclef-2021/train_short_audio/\"\n","            audio_file_path += row.primary_label\n","            if row.primary_label in birds_to_recognise:\n","                outf = output_folder + row.primary_label + \"/\"\n","                if os.path.isdir(outf) == False:\n","                    os.mkdir(outf)\n","                test_list += get_sample('{}/{}'.format(audio_file_path, row.filename), row.primary_label, outf) \n","        except:\n","            raise\n","            print(\"{} is corrupted\".format(audio_file_path))\n","            \n","test_samples = pd.DataFrame(test_list)"]},{"cell_type":"markdown","metadata":{},"source":["**Read all the images as dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T08:06:34.24356Z","iopub.status.busy":"2022-05-17T08:06:34.243234Z","iopub.status.idle":"2022-05-17T08:06:34.373167Z","shell.execute_reply":"2022-05-17T08:06:34.372534Z","shell.execute_reply.started":"2022-05-17T08:06:34.243524Z"},"trusted":true},"outputs":[],"source":["data_dir = \"/kaggle/working/melspectrogram/train/\"\n","batch_size = 32\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  seed=123,\n","  image_size=(216, 216),\n","  batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T07:56:25.545106Z","iopub.status.busy":"2022-05-17T07:56:25.544738Z","iopub.status.idle":"2022-05-17T07:56:25.666193Z","shell.execute_reply":"2022-05-17T07:56:25.665345Z","shell.execute_reply.started":"2022-05-17T07:56:25.545057Z"},"trusted":true},"outputs":[],"source":["data_dir_val = \"/kaggle/working/melspectrogram/validation/\"\n","batch_size = 32\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir_val,\n","  seed=123,\n","  image_size=(216, 216),\n","  batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_dir_test = \"/kaggle/working/melspectrogram/test/\"\n","batch_size = 32\n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir_test,\n","  seed=123,\n","  image_size=(216, 216),\n","  batch_size=batch_size)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T14:58:52.315048Z","iopub.status.busy":"2022-06-05T14:58:52.314745Z","iopub.status.idle":"2022-06-05T14:58:52.349363Z","shell.execute_reply":"2022-06-05T14:58:52.348065Z","shell.execute_reply.started":"2022-06-05T14:58:52.315018Z"},"trusted":true},"outputs":[],"source":["class_names = val_ds.class_names"]},{"cell_type":"markdown","metadata":{},"source":["**For training, choose one of 3 following models**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Baseline Model\n","num_classes = len(class_names)\n","model = Sequential([\n","  layers.Rescaling(1./255, input_shape=(216,216, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Dropout(0.4),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## InceptionV3 Model\n","input_shape = (299,299,3)\n","effnet_layers = InceptionV3(weights=None, include_top=False, input_shape=input_shape)\n","\n","for layer in effnet_layers.layers:\n","    layer.trainable = True\n","\n","dropout_dense_layer = 0.3\n","\n","model = Sequential()\n","model.add(Rescaling(1./255, input_shape=input_shape))\n","model.add(effnet_layers)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(256, use_bias=False))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout_dense_layer))\n","model.add(Dense(37, activation=\"softmax\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T08:07:12.532781Z","iopub.status.busy":"2022-05-17T08:07:12.532456Z","iopub.status.idle":"2022-05-17T08:07:14.711557Z","shell.execute_reply":"2022-05-17T08:07:14.710685Z","shell.execute_reply.started":"2022-05-17T08:07:12.532748Z"},"trusted":true},"outputs":[],"source":["## EfficientNetB0 Model\n","input_shape = (216,216,3)\n","effnet_layers = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n","for layer in effnet_layers.layers:\n","    layer.trainable = True\n","dropout_dense_layer = 0.3\n","\n","model = Sequential()\n","model.add(Rescaling(1./255, input_shape=(216,216, 3)))\n","model.add(effnet_layers)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(256, use_bias=False))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout_dense_layer))\n","model.add(Dense(len(train_df.primary_label.unique()), activation=\"softmax\"))"]},{"cell_type":"markdown","metadata":{},"source":["**Training Part**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T08:07:17.485856Z","iopub.status.busy":"2022-05-17T08:07:17.485585Z","iopub.status.idle":"2022-05-17T08:07:17.491262Z","shell.execute_reply":"2022-05-17T08:07:17.490219Z","shell.execute_reply.started":"2022-05-17T08:07:17.485827Z"},"trusted":true},"outputs":[],"source":["callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.7),\n","             EarlyStopping(monitor='val_loss', patience=5),\n","             ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True)]\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","epoch = 25\n","history = model.fit(train_ds,\n","          epochs = epoch, \n","          validation_data=val_ds,\n","          callbacks = callbacks)"]},{"cell_type":"markdown","metadata":{},"source":["**History Plot**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:55:58.403535Z","iopub.status.busy":"2022-05-17T10:55:58.403105Z","iopub.status.idle":"2022-05-17T10:55:58.507844Z","shell.execute_reply":"2022-05-17T10:55:58.506408Z","shell.execute_reply.started":"2022-05-17T10:55:58.403425Z"},"trusted":true},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(len(acc))\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Test Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate = model.evaluate(test_ds)\n","print(evaluate)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
